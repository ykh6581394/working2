{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f1272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075a8a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\KEARNEY\\\\Desktop\\\\새 폴더\\\\c_project\\\\LDH\\\\code\\\\GCN'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d87aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "\n",
    "def load_data(path=\"../code/\", dataset=\"cora\"):\n",
    "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
    "    print('Loading {} dataset...'.format(dataset))\n",
    "    path = 'C:/Users/KEARNEY/Desktop/새 폴더/c_project/LDH/code/GCN/'\n",
    "\n",
    "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n",
    "                                        dtype=np.dtype(str))\n",
    "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
    "    labels = encode_onehot(idx_features_labels[:, -1])\n",
    "\n",
    "    # build graph\n",
    "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
    "    idx_map = {j: i for i, j in enumerate(idx)}\n",
    "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
    "                                    dtype=np.int32)\n",
    "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(labels.shape[0], labels.shape[0]),\n",
    "                        dtype=np.float32)\n",
    "\n",
    "    # build symmetric adjacency matrix\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "    features = normalize(features)\n",
    "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
    "\n",
    "    idx_train = range(140)\n",
    "    idx_val = range(200, 500)\n",
    "    idx_test = range(500, 1500)\n",
    "\n",
    "    features = torch.FloatTensor(np.array(features.todense()))\n",
    "    labels = torch.LongTensor(np.where(labels)[1])\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "\n",
    "    idx_train = torch.LongTensor(idx_train)\n",
    "    idx_val = torch.LongTensor(idx_val)\n",
    "    idx_test = torch.LongTensor(idx_test)\n",
    "\n",
    "    return adj, features, labels, idx_train, idx_val, idx_test\n",
    "\n",
    "\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21cca004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KEARNEY\\AppData\\Local\\Temp\\ipykernel_20664\\2084789771.py:81: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:591.)\n",
      "  return torch.sparse.FloatTensor(indices, values, shape)\n"
     ]
    }
   ],
   "source": [
    "A, features, labels, idx_train, idx_val, idx_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f28eb0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1abb775",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_layer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, A):\n",
    "        super(GCN_layer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.A = A\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.fc(torch.spmm(self.A, X)) #이웃 정보 종합\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, num_feature, num_class, A):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "                                    GCN_layer(num_feature, 16, A),\n",
    "                                    nn.ReLU(),\n",
    "                                    GCN_layer(16, num_class, A)\n",
    "                                )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.feature_extractor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a02bb0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, Loss, optimizer, num_epochs):\n",
    "    train_loss_arr = []\n",
    "    test_loss_arr = []\n",
    "\n",
    "    best_test_loss = 99999999\n",
    "    best_ACC=1000\n",
    "    final_ACC=0\n",
    "\n",
    "    early_stop, early_stop_max = 0., 10.\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Forward Pass\n",
    "        model.train()\n",
    "        output = model(features)\n",
    "        train_loss = criterion(output[idx_train], labels[idx_train])\n",
    "\n",
    "        # Backward and optimize\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_arr.append(train_loss.data)\n",
    "    \n",
    "        if epoch % 10 == 0:\n",
    "            model.eval()\n",
    "        \n",
    "            output = model(features)\n",
    "            val_loss = criterion(output[idx_val], labels[idx_val])\n",
    "            test_loss = criterion(output[idx_test], labels[idx_test])\n",
    "        \n",
    "            val_acc = accuracy(output[idx_val], labels[idx_val])\n",
    "            test_acc = accuracy(output[idx_test], labels[idx_test])\n",
    "        \n",
    "            test_loss_arr.append(test_loss)\n",
    "        \n",
    "            if best_ACC > val_acc:\n",
    "                best_ACC = val_acc\n",
    "                early_stop = 0\n",
    "                final_ACC = test_acc\n",
    "                print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}, Test ACC: {:.4f} *'.format(epoch, 100, train_loss.data, test_loss, test_acc))\n",
    "            else:\n",
    "                early_stop += 1\n",
    "\n",
    "                print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}, Test ACC: {:.4f}'.format(epoch, 100, train_loss.data, test_loss, test_acc))\n",
    "\n",
    "        if early_stop >= early_stop_max:\n",
    "            break\n",
    "        \n",
    "    print(\"Final Accuracy::\", final_ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7f48265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(FCN, self).__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "                                    nn.Linear(num_feature, 16),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(16, num_class)\n",
    "                                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.feature_extractor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90f303b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], Train Loss: 1.9121, Test Loss: 1.8885, Test ACC: 0.3090 *\n",
      "Epoch [10/100], Train Loss: 0.7556, Test Loss: 1.9785, Test ACC: 0.2050 *\n",
      "Epoch [20/100], Train Loss: 0.5313, Test Loss: 4.8541, Test ACC: 0.3710\n",
      "Epoch [30/100], Train Loss: 0.1605, Test Loss: 7.8023, Test ACC: 0.3500\n",
      "Epoch [40/100], Train Loss: 0.6851, Test Loss: 20.5386, Test ACC: 0.1970 *\n",
      "Epoch [50/100], Train Loss: 0.3729, Test Loss: 16.3366, Test ACC: 0.4040\n",
      "Epoch [60/100], Train Loss: 1.4503, Test Loss: 28.9251, Test ACC: 0.4020\n",
      "Epoch [70/100], Train Loss: 2.2472, Test Loss: 34.7367, Test ACC: 0.3370\n",
      "Epoch [80/100], Train Loss: 0.6101, Test Loss: 23.8472, Test ACC: 0.3400\n",
      "Epoch [90/100], Train Loss: 0.3286, Test Loss: 23.2772, Test ACC: 0.3220\n",
      "Epoch [100/100], Train Loss: 3.6857, Test Loss: 43.5995, Test ACC: 0.3560\n",
      "Epoch [110/100], Train Loss: 2.4076, Test Loss: 50.8979, Test ACC: 0.3670\n",
      "Epoch [120/100], Train Loss: 1.2418, Test Loss: 41.8214, Test ACC: 0.3660\n",
      "Epoch [130/100], Train Loss: 3.4558, Test Loss: 69.5473, Test ACC: 0.3010\n",
      "Epoch [140/100], Train Loss: 2.2635, Test Loss: 76.9218, Test ACC: 0.3460\n",
      "Final Accuracy:: tensor(0.1970, dtype=torch.float64)\n",
      "finish FCN\n",
      "Epoch [0/100], Train Loss: 1.9611, Test Loss: 1.8825, Test ACC: 0.3090 *\n",
      "Epoch [10/100], Train Loss: 1.4480, Test Loss: 1.8434, Test ACC: 0.1500 *\n",
      "Epoch [20/100], Train Loss: 0.8724, Test Loss: 1.5134, Test ACC: 0.3660\n",
      "Epoch [30/100], Train Loss: 0.7694, Test Loss: 1.6939, Test ACC: 0.5750\n",
      "Epoch [40/100], Train Loss: 2.8851, Test Loss: 5.3132, Test ACC: 0.3100\n",
      "Epoch [50/100], Train Loss: 3.2039, Test Loss: 3.8576, Test ACC: 0.3800\n",
      "Epoch [60/100], Train Loss: 4.2996, Test Loss: 5.7741, Test ACC: 0.3290\n",
      "Epoch [70/100], Train Loss: 3.5484, Test Loss: 4.1556, Test ACC: 0.5580\n",
      "Epoch [80/100], Train Loss: 8.7826, Test Loss: 12.6563, Test ACC: 0.4060\n",
      "Epoch [90/100], Train Loss: 7.9737, Test Loss: 10.1437, Test ACC: 0.3740\n",
      "Epoch [100/100], Train Loss: 3.3672, Test Loss: 5.0642, Test ACC: 0.4270\n",
      "Epoch [110/100], Train Loss: 2.8998, Test Loss: 4.3738, Test ACC: 0.2410\n",
      "Final Accuracy:: tensor(0.1500, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# FCN 학습 돌려서 epoch에 따른 Loss 확인\n",
    "import torch.optim as optim\n",
    "\n",
    "model = FCN(features.size(1) , labels.unique().size(0))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1, weight_decay=0.0001)\n",
    "\n",
    "train(model, criterion, optimizer, 1000)\n",
    "\n",
    "print(\"finish FCN\")\n",
    "# GCN 학습 돌려서 epoch에 따른 Loss 확인\n",
    "model = GCN(features.size(1) , labels.unique().size(0), A)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1, weight_decay=0.0001)\n",
    "\n",
    "train(model, criterion, optimizer, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac34cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
